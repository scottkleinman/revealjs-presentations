<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Text Analysis with Lexos</title>

		<meta name="description" content="Slides from my visit to Mark LeBlanc's Computing for Poets class at Wheaton College, March 27, 2016">
		<meta name="author" content="Scott Kleinman">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="../revealjs/css/reveal.css">
		<link rel="stylesheet" href="../revealjs/css/theme/serif.css" id="theme">
		<link rel="stylesheet" href="styles.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="../revealjs/lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( ../revealjs/print-pdf/gi ) ? '../revealjs/css/print/pdf.css' : '../revealjs/css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="../revealjs/lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h2>Text Analysis with Lexos</h2>
					<h4>Computing for Poets<br>March 27, 2016</h4>
					<p class="smaller"><a href="http://scottkleinman.net">Scott Kleinman</a>, California State University, Northridge / <a href="mailto:scott.kleinman@csun.edu">scott.kleinman@csun.edu</a></p>
				</section>
				<section data-transition="concave">
					<section>
					<h3>What is Text Analysis</h3>
					<p class="pull-left">My current definition:</p>
					<p class="pull-left">(Computationally) finding quantitative patterns in natural language samples and attributing meaning to these patterns.</p>
					</section>
					<section>
					<h3>Text analysis is about collaborating with computers.</h3>
					</section>
					<section>
					<h3>But what do we get when we collaborate with computers?</h3>
					</section>
					<section data-transition="convex">
					<p><img src="http://scottkleinman.github.io/revealjs-presentations/DigitalEditingSlideshow/images/HAL9000.jpg"/></p>
					</section>
					<section data-transition="convex">
					<p><img src="http://scottkleinman.github.io/revealjs-presentations/DigitalEditingSlideshow/images/Terminators.jpg"/></p>
					</section>
					<section data-transition="convex">
					<p><img src="http://scottkleinman.github.io/revealjs-presentations/DigitalEditingSlideshow/images/Data.jpg"/></p>
					</section>
					<section data-transition="convex">
					<p><img src="http://scottkleinman.github.io/revealjs-presentations/DigitalEditingSlideshow/images/Romney.jpg" style="height:50%;width:50%;"/></p>
					</section>
				<section>
				<table>
					<tr>
						<td><img src="images/camelota.png" alt="King Arthur and his knights outside Camelot"/></td><td><img src="images/camelot0.png" alt="King Arthur: 'Camelot!'" width="80%" height="80%"/></td>
					</tr>
					<tr>
						<td><img src="images/camelot1.png" alt="Sir Lancelot: 'Camelot!'"/></td><td><img src="images/camelot2.PNG" alt="Sir Galahad: 'Camelot!'"/></td>
					</tr>
					<tr>
						<td colspan="2"><img src="images/camelot3.png" alt="Squire: 'It's only model."/></td>
					</tr>
				</table>
				</section>
				</section>

				<section>
					<h3>Text Analysis Workflow 1</h3>
					<ul>
						<li>Pre-Processing</li>
						<li>Statistical Processing</li>
						<li>Visualisation</li>
						<br/>
						<li>Narrative of Meaning</li>
					</ul>
				</section>
				<section>
					<h3>Pre-Processing</h3>
					<ul>
						<li>Clean up OCR</li>
						<li>Remove metadata, punctuation, digits, stop words</li>
						<li>Transform tokens (consolidation, lemmatisation)</li>
						<li>Slicing and dicing</li>
						<li>Assigning labels</li>
					</ul>
					<p class="pull-left">Pre-processing creates a "deformed" version of the original text for analysis.</p>
				</section>
				<section>
					<h3>Statistical Processing</h3>
					<ul>
						<li>Token counting (e.g. characters, words, n-grams)</li>
						<li>Normalisation (e.g. to compare texts of unequal size)</li>
						<li>Frequency/Probability Comparison (e.g. between the number of times a word occurs in two texts)</li>
						<li>Clustering (identifying groups of tokens/texts with common statistical properties)</li>
						<li>Shape quantitative information about the texts for visualisation/interpretation.</li>
					</ul>
					<p class="pull-left">Statistical processing transforms the text from natural language to quantitative data. This type of “deformance” typically involves dimensionality reduction, a simplification of the data so that it can be represented in two-dimensional space.</p>
				</section>
				<section>
					<h3>Visualisation</h3>
					<ul>
						<li>Arranging quantitative data in graphical format to make it (hopefully) more interpretable than formats in which the data is stored.</li>
						<li>Visualisation is “the reification of misinformation” (Johanna Drucker), so it requires a clear account of the procedures used to make the graph and critical literacy about how to interpret visualisations on the part of the reader.</li>
				</section>
				<section>
					<h3>Narrative of Meaning</h3>
					<ul>
						<li>An account of the significance of the results of text analysis.</li>
						<li>Must include an account of the decisions made as part of pre-processing, statistical processing, and visualisation.</li>
				</section>				
				<section>
					<h3>Text Analysis Workflow 2</h3>
					<ul>
						<li>Re-consider some of the decisions you have made.</li>
						<li>Repeat Text Analysis Workflow 1.</li>
					</ul>
				</section>
				<section>
					<h3>Useful Terminology</h3>
					<ul>
						<li><b>Document:</b> a whole text or a segment of a text.</li>
						<li><b>Token:</b> an individual occurrence of a countable item in a document (typically a word).</li>
						<li><b>Term (also <i>Type</i>):</b> A distinct form of a token that may occur one or more times in a document.</li>
						<li><b>Lemma:</b> The “dictionary headword” form of a token without morphological or spelling variants.</li>
						<li><b>Bag of Words:</b> Set of tokens or terms lacking their order or placement in the original source text(s).</li>
						<li><b>Document-Term Matrix (DTM):</b> A table showing the number of times each term occurs in each document.</li>
					</ul>
				</section>
				<section data-transition="concave">
					<h3>Sample Document-Term Matrix</h3>
					<table>
						<tr>
							<th></th><th>Term 1</th><th>Term 2</th><th>Term 3</th><th>Term 4</th><th>...</th>
						</tr>
						<tr>
							<td>Document 1</td><td>50</td><td>27</td><td>3</td><td>12</td><td></td>
						</tr>
						<tr>
							<td>Document 2</td><td>75</td><td>3</td><td>1</td><td>1</td><td></td>
						</tr>
						<tr>
							<td>Document 3</td><td>64</td><td>1</td><td>1</td><td>1</td><td></td>
						</tr>
						<tr>
							<td>Document 4</td><td>31</td><td>12</td><td>5</td><td>10</td><td></td>
						</tr>
						<tr>
							<td>...</td><td></td><td></td><td></td><td></td><td></td>
						</tr>
					</table>
				</section>
				<section data-transition="concave">
					<h3>A Basic Epistemological Question</h3>
					<p>If each stage is a transformation (“deformance”) of the source text, how do we relate the results of this transformation to the original?</p>
				</section>
				<section>
					<h3>Lexos and Lexomics</h3>
					<p class="pull-left">Lexos is an easy-to-use tool that handles many the basic tasks in a typical text analysis workflow.</p>
					<p class="pull-left">Lexos arose from the Lexomics project, which seeks to use computational approaches to study patterns in literature. Literature and computer science students work alongside one another doing research and developing tools in response to questions generated by the research.</p>
				</section>
				<section data-transition="concave">
					<h3>How to Use Lexos Online</h3>
					<small><a href="http://lexos.wheatoncollege.edu/" target="_blank">http://lexos.wheatoncollege.edu/</a></small>
					<p class="pull-left">You can download the TestSuite files at <a href="http://bit.ly/22FT3Hg" target="_blank">http://bit.ly/22FT3Hg</a>.
				</section>
				<section id="transitions" class="transitions" data-state="trans concave">
					<section data-transition="zoom">
						<h4>Observing the Influence of Orthography in Middle English</h4>
							<p>(Scroll down)</p>
							<a href="http://www.bl.uk/manuscripts/Viewer.aspx?ref=cotton_ms_cleopatra_c_vi_f002r" target="_blank"><img style="height:500px;width:500px;" data-src="images/AncreneWisse.PNG" alt="British Library, Cotton MS Cleopatra C vi, f. 4r"/></a>
							<p><a href="http://www.bl.uk/manuscripts/Viewer.aspx?ref=cotton_ms_cleopatra_c_vi_f002r" target="_blank"><small>British Library, Cotton MS Cleopatra C vi, f. 4r</small></a></p>
					</section>
					<section data-transition="zoom">
						<ul>
							<li><b>Source Texts:</b> In the <code>Middle English</code> folder</li>
							<li><b>Purpose:</b> Determine what effect orthography has on document similarity.</li>
						</ul>
					</section>
					<section>
						<h4>Background</h4>
						<ul style="font-size: smaller;">
							<li>Middle English is characterised by a high number of dialectal features and spelling variations, which can create challenges for computational processing and make comparison difficult.</li>
							<li>The AB language is a term coined in 1929 by J.R.R. Tolkien to refer to the standardised language of two manuscripts of <em>Ancrene Wisse</em>, a guide for anchoresses.</li>
							<li>The language is shared by a group of texts from the English West Midlands including <em>Hali Meiðhad</em> ("Holy Maidenhood"), <em>Sawles Warde</em> ("Refuge of the Souls"), and a life of <em>Saint Juliana</em>.</li>
							<li><em>The Lambeth Homilies</em> is a collection of sermons which also comes from the West Midlands but does not share the AB language forms. <em>The Kentish Sermons</em> come from southeastern England.</li>
							<li>In order explain the dendrogram we get if we compare these texts, it is useful to get a sense of the relative prominence of certain words.</li>
						</ul>
					</section>
					<section>
						<h3>Instructions</h3>
						<ul>
							<li>Go to <b>Manage &gt; Upload</b>. Click Browse and navigate to the <code>MiddleEnglish</code> folder. Upload all the texts.</li>
							<li>Go to <b>Analyze &gt; Clustering &gt; Hierarchical Clustering</b>.</li>
							<li>Enter a <b>Dendrogram Title</b> and click <b>Get Dendrogram</b>. You may need to scroll down to see the result. Notice that the West Midland texts (<em>Ancrene Wisse</em>, <em>Sawles Warde</em>, <em>Juliana</em>, <em>Hali Meiðhad</em>, and the <em>Lambeth Homilies</em>) are split into two clusters. The Kentish Sermons seem to be closer to the <em>Juliana</em> group. How do we know what accounts for this?</li>
							<li>Go to <b>Visualize &gt; MultiCloud</b>. Click <b>Toggle All</b> to select all the texts. Then click <b>Get Graphs</b>. You may need to scroll down to see the result.</li>
							<li>Are there spellings that seem to dominate certain texts? You can drag and drop clouds to re-order them for easier comparison.</li>
							<li>Try the <b>Word Cloud</b> and <b>BubbleViz</b> tools in the <b>Visualize</b> menu for further insight. Can you identify what might be affecting the clustering algorithm?</li>
						</ul>
					</section>
					<section>
						<h3>Instructions (Continued)</h3>
						<ul>
							<li>Go to <b>Prepare &gt; Scrub</b>. Click on the chevron next to consolidations and enter
<pre>þet,þat:þat
ant,and:and</pre>
							Click. <b>Apply Scrubbing</b>. This will consolidate spelling variants of these words into one form each.</li>
							<li>Go to <b>Analyze &gt; Clustering &gt; Hierarchical Clustering</b> and click the <b>Get Dendrogram</b> button.</li>
						</ul>
						<p class="pull-left">Notice that all the West Midlands texts form a single cluster. There is a good chance that the Kentish Sermons most closely resemble the <em>Lambeth Homilies</em> because they share a common genre (sermon). However, the clustering algorithm seems to be more sensitive to the dialectal orthography than to the genre.</p>
						<p class="pull-left">Using word clouds, we have been able to identify what disrupts this pattern in order to obtain clearer results.</p>
					</section>
					<section>
						<h3>Uses of Word Clouds for Document Exploration</h3>
						<ul>
							<li>Get an impression of the content of your documents.</li>
							<li>Identify Stop Words or Other Scrubbing Needs.</li>
							<li>Useful way of conveying token prominence in presentations.</li>
							<li>Can be used to visualise the topics in a topic model (see <b>Visualizing Topic Models</b> below).</li>
						</ul>
					</section>
				</section>
				<section>
					<section>
					<h3>The <em>Pride and Prejudice</em> Experiment</h3>
					<p>(Scroll down)</p>
					<a href="https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/PrideAndPrejudiceTitlePage.jpg/556px-PrideAndPrejudiceTitlePage.jpg" target="_blank"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/1/17/PrideAndPrejudiceTitlePage.jpg/556px-PrideAndPrejudiceTitlePage.jpg" alt="Title page from the first edition of the first volume of Pride and Prejudice" height="486"/></a>
					<br/>
					<small>Source: Lilly Library, Indiana University</small>
					</section>
					<section>
						<ul>
							<li><b>Source Text:</b> In the <code>PrideAndPrejudice</code> folder</li>
							<li><b>Purpose:</b> Examine or compare the frequency of terms over the course of a text.</li>
						</ul>
					</section>
					<section>
					<h3>Background</h3>
						<p class="pull-left">A common task in text analysis is to observe changes in linguistic usage over the course of a text or collection. The Lexos Rolling Windows tool creates a visualisation of these changes.</p>
						<p class="pull-left">For this experiment, we will use a version of Jane Austen's <em>Pride and Prejudice</em> with milestones added at each chapter break. Milestones are strings of text used by Lexos to identify structural divisions. Although we have used chapters, you can place them anywhere in the source text(s).</p>
					</section>
					<section>
						<h3>Rolling Windows</h3>
						<ul>
							<li>Traces the frequency of features within a designated window of tokens over the course of a document.</li>
							<li>Can be used to identify small- and large-scale patterns of usage of individual features or to compare these patterns for multiple features.</li>
						</ul>
					</section>
					<section>
						<h4>Experiment 1:</h4>
						<div class="pull-left">
						<ul>
							<li>Go to <b>Manage &gt; Upload</b> and upload <b>pride_and_prejudice_ms</b> from the <code>PrideAndPrejudice</code> folder. This file has the string <b>Milestone</b> inserted at each chapter break.</li>
							<li>Go to Rolling Windows and select the options represented below:</li>
						</ul>
						<p><b>Count Type:</b> <input type="radio" checked="checked"/> Rolling Average</p>
						<p><b>Unit of Window:</b> <input type="radio" checked="checked"/> Window of Words</p>
						<p><b>Unit of Token:</b> <input type="radio" checked="checked"/> of Word(s)</p>
						<p><b>Size of Rolling Window:</b> <input type="text" value="1000"/>
						<p><input type="checkbox" checked="checked"/> <b>Document has Milestones</b></p>
						<p><b>Milestone Delimiter:</b> <input type="text" value="MILESTONE"/></p>
						<p>Enter a word or words you wish to search.</p>
						</div>
					</section>
					<section>
						<h4>Experiment 2:</h4>
						<div>
						<div class="pull-left" style="width:60%;float:left;">
						<ul>
							<li>Go to <b>Prepare &gt; Scrub</b></li>
							<li>Upload or copy and paste the <a href="http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words" target="_blank">Glasgow stop word list</a>. Click the <b>Apply Scrubbing</b> button.</li>
							<li>Repeat Experiment 1.</li>
						</ul>
						<p style="margin-top:50px;">What changes? Why?</p>
						</div>
						<img src="https://s3.amazonaws.com/epicstreamlive/assets/uploads/videoscover/760x400/pridez.jpg" alt="Pride and Prejudice and Zombies" width="300"style="float:right;"/>
						</div>
					</section>
				</section>
				<section>
					<h3>Visualizing Topic Models</h3>
						<ul>
							<li><b>Source File:</b> <code>Lexos/TestSuite/malletfile/Beowulf_1200-word-topic-counts</code></li>
							<li><b>Purpose:</b> Examine or compare the frequency of terms over the course of a text.</li>
						</ul>
						<p class="pull-left">Topic modelling is a machine learning technique to reverse engineer the "themes" of documents in the form of lists of words (called "topics"). The most common implementation tool is Mallet, but its output is notoriously difficult to visualise. The Lexos MultiCloud tool allows you to upload the Mallet data directly to generate "topic clouds"&mdash;word clouds based on your topics. It even allows you to convert your topics to documents and cluster them.</p>
						<p class="pull-left">The sample Mallet files contain a topic model of the Old English poem <em>Beowulf</em>.</p>
						<p class="pull-left">For further information topic clouds and how to generate them, see <a href="http://scottkleinman.net/blog/2014/07/25/how-to-create-topic-clouds-with-lexos/" target="_blank">How to Create Topic Clouds with Lexos</a> and <a href="http://scottkleinman.net/blog/2015/09/08/how-to-create-and-cluster-topic-files-in-lexos/" target="_blank">How to Create and Cluster Topic Clouds in Lexos</a>.</p>
					</ul>
				</section>
				<section>
					<h3>Other Lexos Functions</h3>
					<ul>
						<li>Download Scrubbed and Cut Files</li>
						<li>Download Workspace for Later Upload</li>
						<li>View or Download Your Document-Term Matrix</li>
						<li>Generate Statistics about Your Corpus</li>
						<li>K-Means Clustering (Forces documents into a set number of topics)</li>
						<li>Select tool to manage active documents (Beta)</li>
						<li>"Topwords" statistical tests for most prominent words (Beta)</li>
					</ul>
					</section>
					<section>
						<h1 class="pull-left">THE END</h1>
						<p class="pull-left">Made with <a href="http://lab.hakim.se/reveal-js/#/">Reveal.js</a>
						</p>
				</section>
			</div>
		</div>

		<!-- Access GitHub Repo -->
<!-- 		<script src="https://code.jquery.com/jquery-2.1.3.min.js">
		</script>
		<script src="Repo.js-master/repo.min.js"></script>
		<script>
			$('#LexosGitHub').repo({ user: 'WheatonCS', name: 'Lexos' });
		</script>-->

		<script src="../revealjs/lib/js/head.min.js"></script>
		<script src="../revealjs/js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,
				viewDistance: 5,

//				transition: 'concave', // none/fade/slide/convex/concave/zoom

    // Parallax background image
    parallaxBackgroundImage: '', // e.g. "reveal-parallax-1.jpg"

    // Parallax background size
    parallaxBackgroundSize: '', // CSS syntax, e.g. "2100px 900px" - currently only pixels are supported (don't use % or auto)

    // This slide transition gives best results:
    transition: 'slide',
				
				// Optional reveal.js plugins
				dependencies: [
					{ src: '../revealjs/lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: '../revealjs/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../revealjs/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: '../revealjs/plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: '../revealjs/plugin/zoom-js/zoom.js', async: true },
					{ src: '../revealjs/plugin/notes/notes.js', async: true }
				]
			});
		</script>
<!--		<script src="https://code.jquery.com/jquery-2.1.3.min.js">
		</script>-->
		<script>
//		Reveal.addEventListener( 'trans', function() {
//			var transitionType = $(".transitions").attr("data-state").replace("trans ", "");
//			var opt = {transition: transitionType};
//			console.log(opt);
//			Reveal.configure(opt);
//		}, false );
		</script>
	</body>
</html>
